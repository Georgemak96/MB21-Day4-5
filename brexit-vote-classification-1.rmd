---
title: "Predicting the brexit vote"
author: ""
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data

- In this exercise, we will work on a classification task of Brexit referendum vote
- The data is originally from British Election Study Online Panel
  - codebook: https://www.britishelectionstudy.com/wp-content/uploads/2020/05/Bes_wave19Documentation_V2.pdf
- The outcome is `LeaveVote` (1: Leave, 0: Remain)

## Libraries

- We will use the following packages

```{r}
library(tidyverse)
library(caret)
library(glmnet)
```

## Load data

We sub-sample the data. Full data takes too much time to estimate for the class... (Feel free to run full sample after the class)

```{r}
set.seed(20200813)
df_brexit <- read_csv("data/data_bes.csv.gz") %>%
  sample_n(3000) # sampling data so
```


## Data preparation

- We will carry out:
  - make `LeaveVote` factor variable
  - test train split
  - preprocess


```{r}
df_brexit <- df_brexit %>%
    mutate(LeaveVote = factor(LeaveVote))
```

### Train-test split

```{r}
train_idx <- createDataPartition(df_brexit$LeaveVote, p = .7, list = F) 

df_train <- df_brexit %>% slice(train_idx)
df_test <- df_brexit %>% slice(-train_idx)
```

### Preprocess

```{r}
prep <- preProcess(df_train %>% select(-LeaveVote), method = c("center", "scale"))
prep

df_train_preped <- predict(prep, df_train)
df_test_preped <- predict(prep, df_test)

```

## Model formulas

There are four logistic regression models  in the manuscript (Table 2).

1. Sociodemographics
2. Identity
3. Anti-elite
4. Attitudes

The following line of codes will generate the each model. 

```{r}
fm_socdem <- formula("LeaveVote ~ gender + age + edlevel + hhincome + econPersonalRetro1")
fm_identity <- formula("LeaveVote ~ gender + age + edlevel + hhincome + 
                        EuropeanIdentity + EnglishIdentity + BritishIdentity")
fm_antielite <- formula("LeaveVote ~ gender + age + edlevel + hhincome + 
              PolMistrust + GovDisapproval + PopulismScale + 
              ConVote + LabVote + LibVote + SNPPCVote + UKIP")
fm_attitudes <- formula("LeaveVote ~ gender + age + edlevel + hhincome + euUKNotRich + 
              euNotPreventWar + FreeTradeBad + euParlOverRide1 + euUndermineIdentity1 + 
              lessEUmigrants + effectsEUTrade1 + effectsEUImmigrationLower")
fm_all <- formula("LeaveVote ~ .")


```

You can use these formulas in a way like:

```{r eval = F}
# for model
socdem<- glm(fm_socdem, data = df_train_preped, family = "binomial")
# for data extraction
model.matrix(fm_socdem, data = df_train_preped) %>% head()

```

## Logistic regression

Run a few models, and evaluate them. Which one has the better predictive performance?

```{r}
###could create a function only with a parameter of fm which prints out the train and test metrics 
socdem<- glm(fm_socdem, data = df_train_preped, family = "binomial")
identity<- glm(fm_identity, data = df_train_preped, family = "binomial")
antielite<- glm(fm_antielite, data = df_train_preped, family = "binomial")
attitudes<- glm(fm_attitudes, data = df_train_preped, family = "binomial")
socdem$fitted.values <- if_else(socdem$fitted.values>0.5,1,0)
socdem_train_metrics <- confusionMatrix(as.factor(socdem$fitted.values),df_train_preped$LeaveVote, positive = "1",mode = "prec_recall")
predict_socdem<- predict(socdem, df_test_preped, type = "response")
predict_socdem <- if_else(predict_socdem>.5,1,0)
socdem_test_metrics <- confusionMatrix(as.factor(predict_socdem),df_test_preped$LeaveVote, positive = "1",mode = "prec_recall")

identity$fitted.values <- if_else(identity$fitted.values>0.5,1,0)
identity_train_metrics <- confusionMatrix(as.factor(identity$fitted.values),df_train_preped$LeaveVote, positive = "1",mode = "prec_recall")
predict_identity<- predict(identity, df_test_preped, type = "response")
predict_identity <- if_else(predict_identity>.5,1,0)
identity_test_metrics <- confusionMatrix(as.factor(predict_identity),df_test_preped$LeaveVote, positive = "1",mode = "prec_recall")

antielite$fitted.values <- if_else(antielite$fitted.values>0.5,1,0)
antielite_train_metrics <- confusionMatrix(as.factor(antielite$fitted.values),df_train_preped$LeaveVote, positive = "1",mode = "prec_recall")
predict_antielite<- predict(antielite, df_test_preped, type = "response")
predict_antielite <- if_else(predict_antielite>.5,1,0)
antielite_test_metrics <- confusionMatrix(as.factor(predict_antielite),df_test_preped$LeaveVote, positive = "1",mode = "prec_recall")

attitudes$fitted.values <- if_else(attitudes$fitted.values>0.5,1,0)
attitudes_train_metrics_logistic <- confusionMatrix(as.factor(attitudes$fitted.values),df_train_preped$LeaveVote, positive = "1",mode = "prec_recall")
predict_attitudes_test_logistic<- predict(attitudes, df_test_preped, type = "response")
predict_attitudes_test_logistic <- if_else(predict_attitudes_test_logistic>0.5,1,0)
attitudes_test_metrics_logistic <- confusionMatrix(as.factor(predict_attitudes_test_logistic),df_test_preped$LeaveVote, positive = "1",mode = "prec_recall")

###the attitudes model seems to be the best and then the identity one the second best
```

## Linear SVM

- Train a linear SVM model, check the predictive performance. How does it compare to the logistic regression?

```{r}
control <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
svm_attitudes <- train(fm_attitudes, data = df_train_preped, method = "svmLinear", tr = control)
predict_attitudes_train_svm <- predict(svm_attitudes)
svm_attitudes_train_metrics <- confusionMatrix(predict_attitudes_train_svm, df_train_preped$LeaveVote, positive = "1", mode = "prec_recall")
predict_attitudes_test_svm <- predict(svm_attitudes, df_test_preped)
svm_attitudes_test_metrics <- confusionMatrix(predict_attitudes_test_svm, df_test_preped$LeaveVote, positive = "1", mode = "prec_recall")

###both the logistic and linear svm attitudes models are very very good in terms of all the metrics
###we can see the two roc auc curves for the test set 
library(pROC)
roc(df_test_preped$LeaveVote, as.ordered(predict_attitudes_test_svm), plot = TRUE, legacy.axes = TRUE, percent = TRUE, xlab="False Positive", ylab = "True Positive",col = "green", lwd = 4,print.auc = TRUE, print.auc.x = 40)
plot.roc(df_test_preped$LeaveVote, as.ordered(predict_attitudes_test_logistic), percent = TRUE, col = "blue", print.auc = TRUE, add = TRUE, print.auc.y = 30)
plot.roc(df_test_preped$LeaveVote, as.ordered(predict_attitudes_test_poly), percent = TRUE, col = "red", print.auc = TRUE, add = TRUE, print.auc.y = 20)
legend("bottomright", legend = c("Svm", "Logistic Regression","Svm Polynomial Kernel"), col = c("green", "blue","red"), lwd = 4)

```


## Polynomial SVM and Radial SVM

- Train non-linear SVM. How is the performance? Any improvement?

```{r cache=T}
poly_svm_attitudes <- train(fm_attitudes, data = df_train_preped, method = "svmPoly", tr = control)
predict_attitudes_train_poly <- predict(poly_svm_attitudes)
poly_svm_attitudes_train_metrics <- confusionMatrix(predict_attitudes_train_poly, df_train_preped$LeaveVote, positive = "1", mode = "prec_recall")
predict_attitudes_test_poly <- predict(poly_svm_attitudes, df_test_preped)
poly_svm_attitudes_test_metrics <- confusionMatrix(predict_attitudes_test_poly, df_test_preped$LeaveVote, positive = "1", mode = "prec_recall")
```


## (Optional) Logistic regression with LASSO

- `glmnet` can run a Logistic model with L1 penalty (LASSO). 
- Try a "full" model combining all inputs.
  - Which inputs survived?

```{r}
df_train_preped_x <- df_train_preped %>% select(-LeaveVote) %>% as.matrix()
df_train_preped_y <- df_train_preped$LeaveVote
df_test_preped_x <- df_test_preped %>% select(-LeaveVote) %>% as.matrix()
df_test_preped_y <- df_test_preped$LeaveVote
lasso_log_reg <- cv.glmnet(df_train_preped_x,df_train_preped_y, alpha = 1, type.measure = "mse", family = "binomial" )
plot(lasso_log_reg)
coef(lasso_log_reg)

###seems that lasso keeps all the attitudes variables
```


